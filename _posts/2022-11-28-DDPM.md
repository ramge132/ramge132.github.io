---
title: Denoising diffusion probabilistic model에 대해서
layout: post
description: paper review
use_math: true
post-image: https://user-images.githubusercontent.com/79881119/235352656-046154f5-8abc-4434-bbcd-c48f4b4ad0b5.gif
category: paper review
tags:
- DDPM
- Generative model
- AI
- Deep learning
---

# Denoising Diffusion Probabilistic Model(DDPM)

## Score matching network

Diffusion model은 score matching network로부터 나왔다고 한다. 그렇다면 대체 score matching network는 무엇일까?

<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054523-a52b7452-4e0e-4fa3-8a19-14724a491fc1.png" width="700"/>
</p> 

Score matching network의 개념을 간단하게 소개하자면 위와 같다. PDF(확률 밀도 함수)의 gradient를 score라고 정의해보자. 이러한 정의에는 energy based 및 normalized probability에 대한 내용이 전제가 되어야 하지만 이거는 아래에서 좀 더 자세히 설명하고 우선 간단하게만 개념을 보자면, gradient는 어떤 함수의 위치에서 정의되고, 그 위치에서 ‘함숫값을 가장 크게 증가시킬 수 있는 방향’으로 정의된다.

그렇기 때문에 흔히 딥러닝에서 사용하는 gradient based learning은 loss 함수의 특정 위치에서의 미분값(그래디언트)을 구하고, 이 그래디언트의 역방향(함숫값을 가장 크게 감소시킬 수 있는 방향)을 통해 loss function을 최적화한다. 이러한 방식을 gradient descent하고 부른다.

마찬가지로 이를 PDF(확률 밀도 함수)에서의 샘플링 관점에서 보면, 확률 밀도 함수의 특정 위치에서 예측한 score(PDF의 그래디언트)가 곧 ‘보다 그럴듯한 샘플’의 방향이 되고, 이 방향대로 샘플을 생성해간다면 궁극적으로는 그럴듯한 샘플을 만들 수 있다는 것이 score matching의 개념이다.

위의 예시 그림을 보면 MNIST(손글씨)를 예시로 가져왔는데, 노이즈로부터 시작하여 점차 gradient를 따라 올라가다보면 깔끔한 샘플이 나오는 과정과 유사하다고 생각하면 된다.

그래서 대체 이런 score matching 개념은 어떻게 나온 것인지, 궁극적으로는 해당 메소드가 DDPM으로 이어지게 된 역사에 대해 설명해드리고자 한다.

## Score matching to NCSN

Energy based 머신러닝 접근법에서는 에너지는 정규화되지 않은 negative log likelihood라고 정의했다. 이에 대한 역함수로 보면 깁스-볼츠만 분포를 정규화하게 되면 확률 분포로 생각할 수 있다는 것

즉 우리가 정말 알고싶은 $p_\theta(x)$에 대해서 알아내는건 어려워서, $p_\theta(x) = \frac{e^{-f_\theta(x)}}{z_\theta}$ 이와 같이 우리가 접근할 수 있는 function $f$에 대한 normlalized probability로 접근하고 싶은 것이고, 여기서의 $z_\theta$는 $e^{-f_\theta(x)}$를 모든 $x$에 대해 적분한 결과가 된다.

\[
z_\theta = \int_{x\sim X} e^{-f_\theta(x)}dx
\]

직접 확률을 구하기 힘들어서 결국에 이런 방식으로 접근을 했는데도 여전히 $z_\theta$를 구하기 힘들다는 문제가 생긴다.

이런 비슷한 문제는 뉴럴 네트워크에서도 똑같이 존재한다. 네트워크를 수많은 파라미터 weight에 대해 최적화하고 싶은데, 결국에 네트워크를 대표하는 ‘함수’ 구조를 analytic하게 표현할 수 없기 때문에 gradient 방식으로 최적화를 진행했던 것이고, 이를 위해 네트워크를 미분 가능한 함수로 정의를 내리고 충분한 데이터로 학습시킨다.

결국 우리가 신경써야할 부분은 모든 $x$에 대해 적분된 $z_\theta$가 아니라 $p_\theta(x)$가 최적화될 방향성이다. 그렇다면 위의 식에 negative log를 취하고 $x$에 대해 gradient를 구하게 되면,

\[
\nabla_x \log p(x) = -\nabla_x f_\theta(x) 
\]

확률의 log likelihood의 gradient에 대해서는 intractable한 부분이 없어진 것을 볼 수 있다. 따라서 좀 더 구체적으로 언급하자면 score matching 방식에서의 score는 probability distribution의 log likelihood를 통해 정의할 수 있는 어떤 함수의 미분이고, 결국 이게 generation의 목적이 된다. 이러한 score matching을 예측하는 score estimation에 대한 방법이 2005년에 소개가 되었고 혹시라도 해당 논문이 궁금한 사람들을 위해 링크를 남겨두도록 하겠다.

[논문링크](https://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf)

논문을 보고 싶지 않은 분들을 위해 간략히 설명드리면, 해당 논문에서는 말 그대로 analytic하게 계산된 결과를 증명해내었고, 증명의 결과 parameter $\theta$에 대해 관련된 term은

\[
\int_x p_{data}(x)\left(\frac{1}{2} (\nabla_x \log p_{\theta} (x))^\top (\nabla_x \log p_{\theta} (x)) - Tr(\nabla_x^2 \log p_{\theta} (x))\right)
\]

위와 같이 정리된다. 결국 문제가 뭐냐면 gradient는 $x$의 차원 수에 따라 연산량이 결정되는데, 이미지와 같이 큰 모달리티에서는 연산 속도가 너무 심하다는 것.

결국 그래서 score matching은 VAE나 flow based, GAN 등 샘플링이 용이한 다른 방법들에 비해 주목받지 못했고, 학습 속도가 생명인 deep learning에서 거의 사용되지 않는 개념으로 마무리될 뻔 했다.

그러다가 이걸 해결하고자 denoising autoencoder 방식을 채택한 NCSN(Noise-conditioning score estimation network)가 등장하였고, 다른 표현으로는 Annealed Langevin dynamics based score matching network라고도 부른다.

해당 논문도 수식이 어마어마하므로 정말 간단하게만 소개하자면, 앞서 score의 jacobian을 구하고 trace를 연산하기가 너무 heavy했기 때문에 Large scale 데이터에 적용하기 힘들었던 기존의 식을 다르게 바꾸었다.

원래의 데이터에 noise 분포를 추가하게 되고(보다 구체적으로는 가우시안 노이즈), 이를 denoising하는 과정으로 원래의 분포를 알 수 있다는 것. 물론 이런 근사화 매커니즘이 성립하려면 각 step에서 추가되는 noise의 크기가 매우 작아야된다.

\[
q_\sigma(\tilde{x}) = \int_x q_\sigma(\tilde{x} \vert x) p_{data}(x) dx
\]

아주 작은 노이즈 분포가 더해졌다는 가정 하에

\[
\nabla_x \log q_\sigma(x) \approx \nabla_x \log p_{data}(x)
\]

이외에도 sliced score matching 방법도 제시되었지만, 해당 방법은 projection에 대해 denoising 방식보다 4배의 cost가 든다는 점에서 따로 설명은 하지 않겠다.

아무튼 이러한 방식을 토대로 원래의 데이터에 미리 정의된 가우시안 분포의 노이즈를 더하고, 이를 제거하는 과정으로 학습을 진행하면 원래의 score matching을 근사시킬 수 있다는 개념이 denoising autoencoder를 활용한 NCSN의 개요.

<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054526-dd0c2779-e177-48a6-a93a-86416c5dfb7a.png"/>
</p> 

샘플링에서는 Markov process 방식을 활용하는데, noise가 추가된 데이터 $\tilde{x}_{t-1}$를 통한 score 예측이 해당 위치에서 다음 샘플로의 방향이 될 것이고(앞서 설명했던 것과 같이 보다 그럴듯한 샘플로의 방향) 여기에 diffusion term $z_t$를 더해주는 것이 Langevin dynamics 방식이다.

\[
  x_t = x_{t-1}+\frac{\epsilon}{2}\nabla_x \log p(x_{t-1}) + \sqrt{\epsilon}z_t
\]

랑쥬뱅 동역학은 brownian motion에서의 SDE solution과 같은 형태다. 많은 증명 과정이 생략된 식인데, 결론적으로 말하자면 SDE solution을 discrete approximation한 형태 중 가장 유명한 식이 위와 같이 표현된 식이다  $z_t$는 평균이 0, 분산이 1인 normal distribution이라고 보면 되고 $\sqrt{\epsilon}$이 표준편차로써 re-parameterization하는 구조가 된다. 그러나 위와 같은 동역학이 가지는 문제

1. Manifold hypothesis
2. Inaccurate score matching in low density region
3. Slow mixing of Langevin dynamics

때문에 실질적으로는 위와 같은 방식 대신 Annealed Langevin sampling 방식을 채택한다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054528-c0577f2d-d1ef-4cd4-b887-7ab175ca8002.png" width="700"/>
</p> 

Manifold 문제란 위와 같이 3차원 공간 상에서 실질적으로 데이터가 2차원 manifold(저차원의 특정 위상이라 보면 된다)에 놓이는 문제로, 이럴 경우 score matching은 고차원의 ambient space에서 정의되기 때문에 제대로 된 샘플링이 힘들다는 가정이다.  Low density region이란, 학습 과정에서 분포의 주가 되는 위치에서는(샘플이 몰려있는 부분) score 예측이 잘되는데, 그게 아닌 부분에서 score 예측이 부정확해진다는 문제고, Slow mixing of Langevin dynamics는 서로 다른 분포가 다른 scale로 weighted mixing되어있는 경우 이에 대한 차이를 샘플링 과정에서 증명할 수 있어야 하는데 기존 Langevin dynamics는 작은 크기의 step size로 이를 증명해낼 수 없다는 문제다.

위의 내용들은 너무 복잡하기 때문에 패스하고, 암튼 그래서 노이즈를 점차 줄여가며 샘플링한다고 생각하면 된다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054531-8fb22553-cf96-4d3d-b0d4-f1b934f321c3.png" width="700"/>
</p> 

더 얘기하고 싶은게 많지만 암튼 이런 denoising하는 형태로 score estimator를 학습할 수 있다고 싶고 넘어가도록 하자.

## What diffusion actually learns?

Diffusion(디퓨전) 모델은 학습에 있어 다음과 같은 목적을 지닌다. 최대한 간단하게 짚고 넘어가기 위해 생성 모델 종류에 대한 그림을 보면 좋을 것 같다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054535-562ac052-0e4a-44f2-9e29-7b05e07b69f1.png" width="500"/>
</p> 

GAN은 생성 모델이 만들어낸 이미지를 기준으로 생성된 가짜 이미지인지, 진짜 데이터 분포에 존재하는 이미지인지 구별자(discriminator)가 구분하는 형태로 생성자를 학습시킨다. 그리고 VAE는 그와는 다르게 embedding space $Z$로 매핑하는 인코더의 도움을 통해 데이터 $x$를 manifold space로 보내고, 이를 활용하여 생성자인 decoder를 학습한다. 이 때, 실제 데이터의 분포인 $p(x)$를 구할 수 없다는 점을 토대로, 실제로 간단하게 정의 가능한 latent space $Z$의 분포를 조건부로 학습하게 된다. 또한 VAE식에서 볼 수 있는 ELBO(Evidence Lower Bound)를 통해 간접적으로 확률을 maximize하게 된다. Flow-based model은 특정 샘플을 latent로 인코딩할 때 사용되는 flow 함수를 정의하고, 만약 이를 정의할 수 있다면 역으로 latent로부터 샘플링이 가능하다는 가정 하에 제안된 형태가 되겠다. 

Diffusion은 이러한 전반적인 생성 모델의 아이디어와 크게는 다르지 않다. Diffusion의 뜻은 확산을 뜻하는데, 흔히 물에 잉크를 한 방울 떨어뜨리거나 공기 중에서 향수가 퍼지는 형태를 생각해볼 수 있다. 이는 곧 브라운 운동(Weiner process)와도 연관되는데, 이러한 형태가 바로 Diffusion에서 말하는 ‘Forward process’, 그리고 이를 통해 역으로 학습된 parameterized network를 통해 노이즈로부터 샘플링을 진행하는 과정은 ‘Reverse process’라고 부른다.

## Forward process in DDPM

DDPM paper에서는 샘플에 노이즈를 점차 더해가는 과정을 forward로 정의했다. 노이즈를 더해가는 과정도 어찌 생각해보면 encoder를 학습하는 것과 같이 reparameterization trick을 사용해서 학습될 수  있는 부분이지만, 해당 논문에서는 이를 또 하나의 가능성으로 두었을 뿐 실제로 실험은 고정된 형태로 forward process에서의 노이즈를 정의했다*.

*실제 논문에서 Experimental detail에서 언급한 형태는 $\beta_t$ scheduling이었는데,  constant, linear, and quadratic($T = 1000$, $\beta_1 = 10^{-4}$ to $\beta_T = 0.02$)라고 한다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054536-5010c130-bfea-43a1-8968-9186013c8799.png" width="700"/>
</p> 

DDPM에서의 forward process는 바로 이전 단계($X_{t-1}$)를 기준으로 다음 단계($X_t$)에 노이즈를 더하게 되는데, 이 과정을 Markov process로 진행하게 된다. 마르코프 과정이란 다음 state가 현재 state에만 의존하는 형태다. 위의 그림에서 볼 수 있듯이 원본 이미지($X_0$)에 아주 작은 노이즈가 더해져서 그 다음 상태인 $X_1$를 만들고, 이를 $T$ 만큼 반복하여 완전한 노이즈($X_T$)가 되도록 하는 과정이다. 논문에서 사용되는 forward process의 term은 $q(X_{t} \vert X_{t-1})$라 볼 수 있다. 논문에서는 미리 정해둔 variance schedule $\beta$를 사용, 이를 통해 다음과 같은 가우시안 노이즈를 더해가는 일련의 프로세스를 $q$로 정의하였다.

\[
q(x_t \vert x_{t-1}) := N(x_t; \sqrt{1-\beta_t}x_{t-1},~\beta_t\rm{I})
\]

## Reverse process in DDPM

DDPM에서 각 $t$에 대해 생성된 노이즈 첨가 샘플들은 이후에도 설명하겠지만 역과정을 학습하기 위한 조건부로 쓰인다. 즉, 우리가 얻고자 하는 생성 모델은 flow based model과 같이 표현하자면 $q(X_{t-1} \vert X_t)$와 같지만, 실제로는 이를 바로 얻을 수 없기 때문에 $p_{\theta}(X_{t-1} \vert X_t)$를 학습하고자 하는 것이다. Forward와 반대로 Reverse는 노이즈로부터 노이즈를 제거하는 작업이 되는데, 결국 특정 신호에 대해서 그보다 매우 작은 가우시안 형태의 잡음을 지속적으로 더하는 과정이나 빼는 과정은 학습되는 분포에 있어서 크게 다르지 않다는 것을 알 수 있기 때문에, 실질적으로 노이즈로부터 샘플을 만들어내는 과정을 모방할 수 있게 되는 것이다. 논문에 나온 표현을 인용하면,

\[
p_{\theta}(x_{0:T}) := p(x_T)\prod_{t=1}^T p_{\theta}(x_{t-1} \vert x_t)
\]

$\theta$로 parameterized된 reverse process network $p_\theta$는, 각 시점의 latent$(x_{1,~2,~\cdots,~T})$를 조건부로 그 다음 state로 샘플링하게 된다. 여기서 각 state에 따라 샘플링하는 과정은 denoising score matching에서의  Langevin dynamics와 유사하다. Langevin dynamics가 사용되는 형태의 논문은 score based model에 대한 논문을 참고하면 좋다. 간단하게만 설명하자면 노이즈를 보고 그 다음 step을 결정하는데, 이 때 step의 방향은 최대한 diffusion model이 학습하는 과정에서 참고한 샘플들의 형태와 유사해지는 형태가 될 것이다.

## How to define Loss function?

위에서 간단하게 언급된 내용을 통해 우리는 결국 $p_\theta$를 최적화하는 게 목적임을 알 수 있다. 모든 딥러닝 모델은 각 학습 형태나 목적에 맞는 loss function(cost function)이 있는데, 이는 바로 VAE에서 사용된 ELBO 식을 참고하면 비교적 쉽게 유도할 수 있다.

\[
  \begin{aligned}
    \log p(x) =& E_{z\sim q(z \vert x)}(\log p(x)) \newline
    =& E_{z} \left(\log \frac{p(x \vert z)p(z)}{p(z \vert x)} \right) \newline
    =& E_{z} \left( \log \frac{p(x \vert z)p(z)}{p(z \vert x)} \frac{q(z \vert x)}{q(z \vert x)} \right) \newline
    =& E_z (\log p(x \vert z))-E_z \left( \log \frac{q(z \vert x)}{p(z)} \right) + E_z \left( \log \frac{q(z \vert x)}{p(z \vert x)} \right)
  \end{aligned}  
\]

$p(x)$를 직접 구할 수 없기 때문에, 우리는 미리 알고 있는 $z$를 통해 이를 추정 가능하다고 생각하는 것이다.  Prior $z$에 대해서 $p(x)$를 조건부로 알게 되는 $p(x \vert z)$를 likelihood로 삼아 posterior로 나눠주게 되면 추정할 수 있는 것이다. 그런데 $x→z$ 과정은 encoding, $z → x$ 과정은 decoding으로 정의할 수 있으며, 실제로는 Encoder인 p가 forward process를, Decoder인 q가 reverse process를 담당하기 때문에 이를 사용하여 KL divergence 식을 만들어낼 수 있다. 실제로 획득하기 힘든 역과정에 대해서 decoder의 시작점인 $z$의 분포를 알고 있다면 encoder가 이러한 분포를 따라가게끔 학습하면 될 것이고, DDPM과는 다르게 VAE에서 encoder와 decoder는 모두 학습 가능한 파라미터인 $\phi$ 와 $\theta$ 로 정의된다.

\[
  =E_z ( \log p_{\theta}(x \vert z)) - D_{KL} (q_{\phi}(z \vert x) \vert\vert p(z)) + D_{KL} (q_{\phi}(z \vert x) \vert\vert p(z \vert x))
\]

Variational Autoencoder의 주목적인 ‘Variational bayes’는 접근하기 힘든(intractable이라고 한다) posterior $p_\theta(z \vert x)$를 encoder의 도움을 통해 획득하고자 하는 것이다. 따라서 Generation 관점에서는 maximum likelihood(MLE) $P_\theta(x \vert z)$이지만, 사실 이러한 학습은 굳이 VAE 학습법이 아니더라도 adversarial하게 학습이 가능한 GAN이라던지 등 다른 알고리즘으로 궁리해볼 수 있다. 아무튼 여기서 중요한 것은, VAE는 인코더의 도움을 받아서 디코더의 posterior를 학습시켰다는 것.

이러한 관점을 조금만 denoising diffusion probablistic model로 옮긴다면 비슷한 optimization을 생각해볼 수 있다.

기존의 ELBO 식에서의 latent를 time dependent variable $x_t$로, image domain은 $x_0$로 정의한다.

여기서 time $t$는 $x_0$를 기준으로 노이즈가 ‘얼마나’ 더해졌는지를 나타내는 수치라고 보면 된다.

\[
    =E_z(\log p_{\theta}(x_0 \vert x_t)) - D_{KL} (q(x_t \vert x_0) \vert\vert p_{\theta}(x_t)) + D_{KL} (q(x_t \vert x_0) \vert\vert p_{\theta}(x_t \vert x_0))
\]

아까도 말했듯이 likelihood model에서는 posterior를 획득할 수 없다는 걸 알기 때문에,  식에서의 $p(x_t \vert x_0)$는 처리할 수 없었다. 따라서 이 뒷부분을 $D_{KL} \ge 0$로 두고 나머지 항들을 통해 lower bound를 정의한 식이 바로 Variational bound이다. 이를 score matching based인 DDPM에서는 조건부를 통해 처리가 가능하다. 이를 실제 식으로 유도해보기 위해 약간의 트릭을 써보도록 하자.

앞에 있는 $\log p_\theta(x_0 \vert x_t)$를 $z$에 대해 평균을 내는 부분과 바로 뒤쪽에 있는 KL divergence의 분모 부분을 바꿀 수 있다. 이때 뒤에 있는 $D_{KL} \ge 0$을 무시하고 확인해보도록 하겠다.

\[
    \ge E_{x_T}(\log p_\theta(x_t)) - D_{KL} (q(x_t \vert x_0) \vert\vert  p_{\theta}(x_0 \vert x_t))
\]

위와 같이 변하게 되고, 이걸 fianl $T$에 대해서 일반화해서 보면,

\[
  \begin{aligned}
    \mathcal{L} :=& E\_{x\_T}(-\log p\_\theta(x\_0)) \newline
    \mathcal{L} \le& \mathbb{E}\_{x\_T}\left(-\log \left(\frac{p(x\_0 \vert x\_T)}{q(x\_T \vert x\_0)} \right) \right) \newline
    \mathcal{L} \le& \mathbb{E}{x\_T}\left(-\log \left(\frac{p\_\theta(x\_T \prod_{t=1}^T p\_\theta(x\_{t-1}\vert x\_t))}{\prod\_{t=1}^T q(x\_t \vert x\_{t-1})} \right) \right)
  \end{aligned}  
\]

처럼 graphical modeling이 가능하고

이를 쭉 정리하다보면,

\[
    \mathcal{L} \le \mathbb{E}{x_T}\left(-\log (p_\theta(x_T))-\sum_{t=2}^T \log \frac{p_\theta(x_{t-1} \vert x_t)}{q(x_t \vert x_{t-1})} -\log \frac{p_\theta(x_0 \vert x_1)}{q(x_1 \vert x_0)} \right)
\]

와 같이 정리 가능하다.

여기서 정리한 부분에서 가장 메인이 되는 건 t = 2인 부분인데, 이는 t=2일 때부터 $x_t$는 $x_0$에 무관한 조건화가 가능하다. 따라서 위의 식에서의 pre-defined posterior를 likelihood로 대체 가능하다.

\[
    \mathcal{L} \le \mathbb{E}{x_T}\left(-\log (p_\theta(x_T))-\sum_{t=2}^T \log \left( \frac{p_\theta(x_{t-1} \vert x_t)}{q(x_{t-1} \vert x_t, x_0)} \times \frac{q(x_{t-1} \vert x_0)}{q(x_t \vert x_0)} \right) -\log \frac{p_\theta(x_0 \vert x_1)}{q(x_1 \vert x_0)} \right)
\]

요 식을 다시 잘 지지고 볶아서 다음과 같이 만들면, loss에 대한 공식 유도는 모두 끝난다.

\[
\mathcal{L} \le \mathbb{E}{x_T}\left(-\log \left(\frac{p_\theta(x_T)}{q(x_T \vert x_0)} \right)-\sum_{t=2}^T \log \left( \frac{p_\theta(x_{t-1} \vert x_t)}{q(x_{t-1} \vert x_t, x_0)} \right) -\log p_\theta(x_0 \vert x_1) \right)
\]

<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054537-af41bf59-2883-4ad9-8cc8-fedb83fb35ee.png" width="700"/>
</p> 

맨 앞에 있는 negative log likelihood는 결국 x_0로부터 노이즈를 쭉 만드는 과정에서 gaussian 분포를 따라가게끔 하고, 역과정에서는 gaussian 분포를 시작으로 샘플링을 하겠다는 것, 즉 VAE에서의 regularization term이라고 보면 된다( forward process → gaussian).

두 번째 $\sum$이 있는 식은 중간의 초록색 부분으로, 각 reverse process 에 대한 예측을 이미 정의된 forward process에 맞추는 과정이다. 그리고 마지막 항은 $x_1$로부터 진짜 이미지에 해당하는 $x_0$로 reconstruction하는 부분이라고 보면 된다.

\[
  q(x\_{t-1} \vert x_t,~x_0) = q(x_t \vert x_{t-1}) \times \frac{q(x_{t-1} \vert x_0)}{q(x_t \vert x_0)} = N(x_{t-1}; \tilde{\mu}\_t(x_t, x_0), \tilde{\beta}\_t I)  
\]

\[
  \tilde{\mu}\_t(x_t, x_0) := \frac{\sqrt{\bar{\alpha}\_{t-1}}\beta\_t}{1-\bar{\alpha}\_t}x_0 + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}\_{t-1})}{1-\bar{\alpha}\_t}x_t  
\]

\[
  \tilde{\beta}\_t := \frac{1-\bar{\alpha}\_{t-1}}{1-\bar{\alpha}\_t}\beta_t
\]
 

Tractable한 항에 대한 정리는 위와 같다. 위 공식에 대한 유도는 논문을 참고하면 단순히 gaussian 분포의 조건부로 해결 가능한 수식이다.

\[
  L_{t-1}:= \mathbb{E}\_{x_T} \left( \log \left( \frac{q(x_{t-1} \vert x_t, x_0)}{p\_{\theta}(x_{t-1} \vert x_t)} \right) \right) = \mathbb{E}\_{x_T \sim q(x_t \vert x_0)} \left( \frac{1}{2\sigma^2_t} \parallel \tilde{\mu}\_t (x_t, x_0) - \mu\_\theta (x_t, t) \parallel^2 \right) + C
\]

따라서 결국에 위와 같은 식을 최적화하는 것이 목표가 되고, 각 step $t$에서 다음 방향으로의 gaussian 분포를 예측하게 된다. 기존의 loss function은 가우시안 분포 사이의 KL divergence로 구성이 되는데, 이는 결국 noise의 variance를 최소화시키고 time step $T$를 키움으로써 reverse process가 효과적으로 가우시안 분포를 따를 수 있기 때문이다. 모델이 예측해야할 요소는 input에 대한 평균값인데, 이 또한 다음과 같이 단순화할 수 있다.

\[
  L_{t-1} -C := \mathbb{E}\_{x_0, \epsilon} \left( \frac{\beta_t^2}{2\sigma_t^2 \alpha_t (1- \bar{\alpha}\_t)} \parallel \epsilon - \epsilon\_\theta (\bar{\alpha}\_t x_0 + \sqrt{1 - \bar{\alpha}\_t}\epsilon, t) \parallel^2 \right)  
\]

\[
  \mathcal{L}\_{simple} := \mathbb{E}\_{x_0, \epsilon} \left( \parallel \epsilon - \epsilon\_\theta(\sqrt{\bar{\alpha}\_t}x_0 + \sqrt{1- \bar{\alpha}\_t}\epsilon, t) \parallel^2 \right)
\]

위의 식과 같이 $\epsilon \sim N(0, I)$에 대한 식으로 정리할 수 있는데, 이를 그대로 최적화에 사용하는 것과 simple(normalization term $\gamma$를 없애는 식)을 최적화해도 괜찮다고 했다. 이는 NCSN과는 다른 접근이었던게, NCSN에서는 각 step을 모두 정규화하여 weighted loss를 구해주었는데, 굳이 그럴 필요 없다는 것을 DDPM에서는 실험적으로 증명하였다.
<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054546-0c6c4106-b3ab-4f39-b96a-baba143c252b.png" width="500"/>
</p> 

그게 바로 baseline과 다른 요 방식. 성능이 더 잘나왔다고 한다.

## Limitations
<p align="center">
  <img src="https://user-images.githubusercontent.com/79881119/209054548-87a67aa8-fdc5-4f4d-9f3f-deea212d5b20.png" width="900"/>
</p> 

DDPM은 초창기 논문이다 보니 한계점이 되게 많은데, 그 중 하나가 pixel level interpolation이다. 보통 GAN같은 generative model에서는 latent space에서 interpolation을 진행하더라도 생성 이미지의 consistency(일관성)이 유지가 되었는데, DDPM은 어쩐 이유에서인지 낮은 level에서 interpolation을 진행하면 아예 다른 이미지가 만들어진다고 한다. 아무래도 조금씩 노이즈를 제거해가는 샘플링 방식을 사용하는 DDPM에서는 implicit model이 하나의 step($t → t-1$)에 대해서만 최적화가 가능하기 때문에 최종적으로 생성되는 이미지인 $x_0$에 대해서는 낮은 level의 latent가 이를 인지할 수 없다는 생각이다. 이러한 문제를 이후 DDIM에서 implicit, non-Markovian sampling 방식을 통해 해결할 수 있다고 주장하였다.

또다른 한계점으로는 sampling 속도 및 학습 속도라 할 수 있겠다. 물론 학습 과정에서 시간이 소모되는 건 어느 딥러닝 과제에서나 매한가지이지만, 샘플링 자체가 오래 걸리는 건 생성 모델로 사용되기에 매우 큰 단점으로 꼽힌다. 이러한 문제 역시 이후 DDIM이 해결하였고, 현재 대부분의 diffusion sampler 방식은 DDIM을 사용하고 있다(DDIM도 이후 글로 리뷰해서 올려볼 예정이다).
