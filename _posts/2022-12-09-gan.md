---
title: Generative adversarial networks(GAN)에 대하여
layout: post
description: Adversarial approach on generation task
post-image: https://user-images.githubusercontent.com/79881119/235353010-a64c9794-7dd9-4656-a691-fa99127f6e0c.gif
category: paper review
use_math: true
tags:
- AI
- deep learning
- generative model
- adversarial training
---

이번 게시글에서는 생성 모델 중 하나인 GAN(Generative Adversarial Networks)에 대해 다룰 예정이다. 앞서 다른 생성 모델들인 VAE, Diffusion에 대해서는 모두 소개했었는데 가장 유명하고 가장 많이 연구된 GAN을 빼먹었다는게 아쉬워서 들고 왔다. GAN 연구는 여전히 활발히 진행 중이며 StyleGAN과 같이 스타일에 따른 이미지 생성 모델 뿐만 아니라 3D scene aware GAN이나 depth map generation 등 다양한 분야에서 활용되고 있다. GAN이 가장 좋은 점은 샘플링 속도가 빠르다는 점에 있다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209054535-562ac052-0e4a-44f2-9e29-7b05e07b69f1.png" width="600"/>
</p>
---

# Background knowledge
생성 모델은 원하는 데이터의 분포를 얻는 과정이다. 그렇기 때문에 likelihood based network는 아니지만 GAN 또한 approach 자체는 유사한 분포를 구성하고자 하는 방향이고, 그렇기 때문에 흔히 latent space라고 하는 $\mathcal{Z}$로부터의 $\mathcal{X}$ mapping이 정의된다. 이러한 부분에서 꼭 짚고 넘어가야할 확률에 대한 사전 지식에 대해 보도록 하자.

## Probability

<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089630-707703f9-2742-4366-b3ef-30b00bdc23a4.png" width="600"/>
</p>
위의 그림에서 붉은색으로 표시된 부분이 확률 변수 $y \sim \mathcal{N}(0, 1)$이라고 보고 파란색으로 표시된 부분이 확률 변수 $x \sim \mathcal{N}(0, 0.5)$라고 해보자. 둘 다 간단하게 이해해보기 위해 가우시안 분포로 가정하였다.   
우리는 두 변수 $x,~y$에 대해 중간 분포를 정의할 수 있고, 이를 joint probability라 부르는 $p(x,~y)$로 정의할 수 있다. 여기서 중요한 점은 변수 $x$와 $y$가 서로 관련될 수도 있고, 그렇지 않을 수도 있다. 두 확률 분포 $p(x)$와 $p(y)$의 joint는 그림에서 보는 것과 같이 중간 평면 상에서의 입체적인 가우시안 형태로 나타난다. 가우시안은 평균을 기준으로 대칭이기 때문에 해당 joint는 isotropic한 특징을 가진다.   
해당 joint distribution($p(x,~y)$)을 각 축으로 projection하게 되면 원래 분포인 $p(x)$와 $p(y)$를 얻을 수 있다. 이는 다음과 같은 식으로 표현 가능하다.
\[
    \begin{aligned}
        \int_{-\infty}^{\infty} p(x,~y) dy =& p(x) \newline
        \int_{-\infty}^{\infty} p(x,~y) dx =& p(y)
    \end{aligned}    
\]
물론 이는 연속인 확률 밀도 함수에 대한 표현이고, 만약 이산 확률 질량 함수에 대한 표현으로 바꾸면,
\[
    \begin{aligned}
        \sum_{y} p(x,~y) =& p(x) \newline
        \sum_{x} p(x,~y) =& p(y) \newline
    \end{aligned}    
\]
위와 같다. 다차원에서 특정 축을 기준으로 적분한다는 것은 해당 축을 따라서 모두 더하는 것이므로 projection이 된다.   
앞서 말했던 것과 같이 두 개의 변수는 서로 연관되어 있을 수도 있다. 만약 서로 무관하다면(지나가는 사람이 내 이상형일 확률과 내일 비가 올 확률 정도의 관계) 상관없지만, 그렇지 않을 경우 조건부 확률이 marginal이나 joint와는 다르게 유의미한 형태로 나타난다. 이를테면 변수 $x$가 어떤 값을 가질 때의 변수 $y$의 확률을 나타내는 식은,
\[
    p(y \vert x) = \frac{p(x,~y)}{p(x)}    
\]
위와 같다.

## PDF(확률 밀도 함수) modeling and sampling
그렇다면 특정 분포를 모델링하고, 모델링된 파트에서 샘플링을 어떻게 해야할까? 다음과 같은 순서로 볼 수 있다.
1. 분포를 예측하고 싶은 Samle data가 있다.
2. Sample data로부터 empirical하게 PDF를 구한다.
3. Empirical하게 구한 PDF를 Standard PDF와 피팅시킨다.
4. 이 과정에서 parameter를 예측한다. 예측하는 방식은 Maximum likelihood estimation(MLE), Bayesian estimation 등등...

그리고 샘플링은 이렇게 구한 PDF로부터 역으로 구하는 것이다. $p(x) \rightarrow x$.   
사실 이렇게만 말하면 아직 MLE나 Bayesian에 대해서 제대로 짚고 넘어오지 않았기 때문에 이해가 잘 되지 않는다. 일단 넘어가도록 하자.

---

# Generative and Discriminative models
<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089636-7a1f4e2e-6f0d-4af2-97c6-fe44d0271457.png" width="600"/>
</p>
GAN을 그냥 간단하게 한마디로 설명하자면 생성자라고 불리는 Generator($G$)와 구별자라 불리는 Discriminator($D$)가 서로 치고박고 싸우게 하면서 성능을 높이는 것이다. 바쁘다바빠 현대사회 경쟁사회에서 다들 취업이니 스펙이니 신경쓰면서 자기개발에 힘쓰는 시대이지 않은가. ~~뭔 관계인지는 모르겠지만~~   
암튼 GAN을 구성하는 요소들 중에서 generator와 discriminator에 대해 알아볼 필요가 있다. Generative model은 joint PDF인 $p(x,~y; \theta)$로 표현되거나 marginal PDF $p(x; \theta)$로 표현된다. 모든 딥러닝 네트워크는 implicit하게 함수를 학습하는데, 이때 generator는 분포를 만드는 $\theta$를 학습한다고 생각해주면 된다. 그와는 다르게 discriminative model은 conditional PDF인 $p(y \vert x; \theta)$를 학습하게 되고, generative model이 내보낸 그럴 듯한 모달리티(데이터) $x$에 대해 구분하는 작업이 되겠다. 그래서 표현 자체로는 parameter $\theta$를 동일하게 사용했지만, 좀 더 엄밀히 말하자면 generative model과 discriminative model은 서로 다른 parameter set $\phi \in \Phi$, $\theta \in \Theta$에 대한 최적화라 보면 된다. Generative model에는 [GMM](https://jontemple.org.uk/wp-content/uploads/2020/06/bht10.pdf), [HMM](https://web.stanford.edu/~jurafsky/slp3/A.pdf) 그리고 [Bayesian Networks](https://www.bu.edu/sph/files/2014/05/bayesian-networks-final.pdf), [Deep belief networks](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf), 뭐 [Deep Boltzmann machine](http://www.cs.toronto.edu/~fritz/absps/dbm.pdf) 등등이 있다.   
그리고 discriminative model에는 흔히 알고있는 low level task를 담당하는 MLPs, CNNs, Logistic regression, SVM 등등 모든 형태의 encoder로 볼 수 있다.

---

# General concept of data generation with generative models
그냥 일반적인, 모든 형태의 생성 모델이 하고자 하는 방향성에 대해 일반적인 컨셉을 설명하자면 다음과 같다. 우리는 디코더 형태를 지닌 generator network를 통해 그럴듯한 데이터 $x$를 만들고 싶고, 앞서 설명했던것과 같이 generator는 $p(x; \theta)$를 학습한다. 이때, 실질적인 real dataset probability를 구하기 힘들기 때문에, 이에 대한 joint $p(x,~z)$를 상정하고 싶은 것이고, Bayesian에 대해 우리가 접근할 수 없는 확률들과는 관계없이 최적화하자는 것이다.
\[
    p(z \vert x) = \frac{p(x \vert z)p(z)}{p(x)}    
\]
<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089637-f5d977b6-2a78-4338-9ae1-b880fa281f83.jpg" width="600"/>
</p>
다만 Likelihood($p(x \vert z)$) 최적화 관점이 아니라 여기서는 $p(x)$에 집중한다. 즉 joint를 모든 $z$에 대해 적분한 것은 곧 likelihood를 우리가 미리 정해놓을 수 있는 marginal likelihood 변수 $z \sim p(z)$에 대한 평균을 보자는 것이다.
\[
    p(x) = \int_z p(x \vert z) p(z) dz
\]
그렇게 정하는 방식이 곧 normal distribution에서의 샘플링 $p(z) = \mathcal{N}(0, I)$이고, 이렇게 추출된 $z$를 **latent vector** 혹은 **latent variable**이라 부른다.   
추출된 latent를 generator에 통과시킨 결과가 $p(z)p(x \vert z)$에 대한 샘플이 되니까, 아까 앞서 말했던 background에서와 같이 empirical PDF에 피팅하는 과정이라 볼 수 있다.

---

# GAN의 특징
[GAN 가장 첫 논문](https://arxiv.org/abs/1406.2661)을 보면 모든 컨셉이 다 나와있다. 가장 먼저 모델은 implicit PDF를 학습한다. $x$를 만들기 위해 따로 joint probability에 대한 supervision을 주지 않기 때문에 unsupervised approach라고 할 수 있다.   
그리고 네트워크는 총 두 개로 구성이 되고, generative network인 $G$와 discriminative network인 $D$가 서로 경쟁하는 구조가 된다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089638-4006e341-97bf-45f2-9204-8e23b3a0c4e4.png" width="600"/>
</p>
이걸 흔히 위조지폐범과 이를 잡아내는 경찰로 비유하는데, generator(위조지폐범)는 그럴 듯한 거짓 데이터(위조지폐)를 만들어내기 위해 노력하고, discriminator(경찰)은 진짜 데이터와 거짓 데이터(위조지폐와 실제 화폐)를 구분하는 형태로 경쟁적인 학습을 한다. 이를 표현한 것이 mini-max GAN이며 optimization loss는 다음과 같다.
\[
    \begin{aligned}
        &\min_G \max_D V(D,G) \newline
        V(D,G) =& E_{x \sim p_{data}(x)}(\log D(x)) + E_{z \sim p_z(z)}(\log (1-D(G(z))))
    \end{aligned}    
\]
표현식에서 $\log (\cdot)$는 흔히 확률을 energy based로 최적화할 때 사용하는 log liklihood라 보면 되고, 확률은 $0 \sim 1$의 값을 가진다고 생각하면 된다.
  
## Discriminator의 입장
실제 데이터 분포인 $p_{data}(x)$ 로부터 온 $x$는 discriminator로 하여금 진짜다(True = 1)라고 판별되어야 하기 때문에, discriminator 입장에서 최적화가 되었을 때 가장 이상적인 $\log D(x)$은 0이다.   
마찬가지로 latent variable $z \sim p(z)$를 사용해서 생성한 가짜 데이터 $G(z)$는 discriminator로 하여금 가짜다(False = 0)라고 판별되어야 하기 때문에, discriminator 입장에서 최적화가 되었을 때 가장 이상적인 $\log(1-D(G(z)))$는 0이다.   
즉 Discriminator는 $V(D, G)$ 식을 최대화하고 싶어한다. 여기서 0을 만드는게 왜 최대화지?라고 고민이 된다면, $\log$ 함수에 들어가는 값이 $0 \sim 1$ 사이의 확률값이기 때문에 치역이 $-\infty \sim 0$임을 고려해주면 좋을 것 같다.   

## Generator의 입장
Generator는 $V(D ,G)$의 두 term 중에서 뒤의 term에만 관련이 있다. Generator의 입장에서는 자신이 latent variable $z$로부터 생성한 가짜 데이터 $G(z)$가 discriminator를 속여야 하므로(가짜 데이터를 보고 '어 이건 찐인데?' 해야 한다는 것), generator 입장에서 최적화가 되었을 때 가장 이상적인 $\log (1 - D(G(z)))$는 $-\infty$이다.

---

위의 두 내용을 종합했을 때 mini-max optimization 식을 이해할 수 있다. 서로 최적화하고자 하는 방향성이 다르기 때문에 치고 박고 싸우는 과정에서 파라미터가 알아서 optimization된다는 것.
<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089640-17906d02-f7bf-42e6-ad86-01d2a8c5d04c.png" width="400"/>
</p>
따라서 한쪽 축으로 보면 convex optimization, 다른 축으로 보면 concave optimization이 되어 궁극적으로는 global point로 하여금 saddle point에 머무르는 것이다.   
이를 보다 직관적으로 보여주는 그림이 GAN 논문에 첨부되어있다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089642-86c8cfec-0767-498e-b5ae-63892418363d.png" width="800"/>
</p>
파란색으로 나타나있는 분포가 discriminator가 그리는 분포이며, 검은색으로 나타나있는 분포가 real data의 distribution, 초록색으로 나타나있는 분포가 generator가 생성한 데이터에 대한 분포이다. (a)를 보면 학습 초반에는 generator, discriminator 모두 최적화가 안된 상태이므로 $z \rightarrow x$ mapping(초록색 분포)도 실제 데이터(검은색 점)를 잘 따라가지 못하며, discriminator도 얼추 구분은 하지만 완벽하게 진짜/가짜 샘플에 대한 확신을 못하고 변동이 큰 것을 볼 수 있다.   
Discriminator 학습이 어느 정도 진행되면 (b), discriminator는 이제 진짜/가짜 샘플에 대한 구분을 잘 하게 된다.   
이 상태에서 Generator를 학습시키면 (c), $z \rightarrow x$ mapping이 보다 초록색 분포를 검은색 점에 가깝게 만드는 걸 확인할 수 있다.
학습이 마무리되면, generator는 완전히 실제 분포에 가깝게 mapping을 할 수 있게 되며 discriminator는 진짜/가짜 샘플에 대해 완전히 구분할 수 없게 된다. 바로 이 지점이 위에서 언급한 saddle point, global optimization이다.
<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089644-847cd2b8-e9e0-4c2b-a8db-6dd7149edf66.png" width="800"/>
</p>
알고리즘을 보면 위와 같다. 실제로 학습할 때는 discriminator를 generator에 대해 $K$ 번 optimize하고, generator를 1번 optimize하는 방식을 사용했다. 그래서 위에서 봤던 분포를 기준으로 하면 실제 학습은
\[
\text{Training iterations} \times (K \times \text{((a)} \rightarrow \text{(b))} \rightarrow 1 \times \text{(c))} = \text{(d)}
\]
라고 볼 수 있다.

---

# Optimize expression as JS(Jensen-Shannon) divergence
앞서 언급했던 식을 유도하면 JS divergence 식으로 만들 수 있다.
\[
    \begin{aligned}
        C(G) =& \max_D V(G,~D) \newline
        =& E_{x \sim p_{data}}(\log D_G^\* (x)) + E_{z \sim p_z}(\log(1-D_G^\*(G(z)))) \newline
        =& E_{x \sim p_{data}}(\log D_G^\* (x)) + E_{x \sim p_g}(\log(1-D_G^\*(x))) \newline
        =& E_{x \sim p_{data}} \left( \log \frac{p_{data}(x)}{p_{data}(x)+p_g(x)} \right) + E_{x \sim p_g} \left( \log \frac{p_g(x)}{p_{data}(x)+p_g(x)} \right)
    \end{aligned}    
\]
앞선 식과 차이가 있다면 generator가 만드는 분포 자체를 $p_g$로 상정해버린 것이다. 실제로는 $z \rightarrow x$ mapping이 전제되는 부분을 generator term을 없애버리면서 이처럼 바꿀 수 있게 된다. 여기에 우리가 알고 있는 사실 하나는, 최적화가 되었을 때 $p_g = p_{data}$라는 것이고, $D_G^\* = \frac{1}{2}$이다. 해당 value들을 위의 식에다가 적용하면,
\[
    \begin{aligned}
        C(G) =& E_{x \sim p_{data}} \left( \log \frac{p_{data}(x)}{p_{data}(x)+p_g(x)} \right) + E_{x \sim p_g} \left( \log \frac{p_g(x)}{p_{data}(x)+p_g(x)} \right) \newline
        =& E_{x \sim p_{data}} \left( \log \frac{p_{data}(x)}{\frac{p_{data}(x)+p_g(x)}{2}} \times \frac{1}{2} \right) + E_{x \sim p_g} \left( \log \frac{p_g(x)}{\frac{p_{data}(x)+p_g(x)}{2}} \times \frac{1}{2} \right) \newline
        =& -\log(4) + D_{KL}\left( p_{data} \parallel \frac{p_{data}(x)+p_g(x)}{2} \right) + D_{KL} \left( p_g \parallel \frac{p_{data}(x)+p_g(x)}{2} \right) \newline
        =& -\log(4) + 2 \cdot D_{JS}(p_{data} \parallel p_g)
    \end{aligned}    
\]

---

<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089648-4373578b-2637-4b8c-8c1a-b01a834f48a7.png" width="800"/>
</p>
생성된 결과물이다. MNIST, TFD 그리고 CIFAR-10에 대해 실험하였다.

---

# Measure metrics for GANs
GAN은 생성 모델이다. 그렇기 때문에 discriminator인 모델들이 supervision을 통해 얻을 수 있는 정량적 평가 방식이 통하지 않는다. 생성 모델이라고 하면 단순히 이미지를 잘 만드는 것에 그치는게 아니라 얼마나 다양하고, 그러면서도 있을 만한 이미지를 만들어야 하기 때문에 이를 측정할 수 있는 지표가 필요하다. GAN evaluation에는 일반적으로 약 3개의 meric이 사용된다.

## IS: Inception Score
IS라 불리는 inception score는 quality와 diversity를 측정한다.
\[
    IS(G) = exp(E_{x \sim G} (D_{KL}(p(y \vert x), p(y))))    
\]
만약 생성된 이미지가 다양하다면, 그에 따른 분포 $p(y)$는 고르게 퍼져 있어야 한다. 즉, 엔트로피가 커야 한다. 해당 부분이 판단하는 것이 곧 이미지의 다양성이다. 마찬가지로 generated image $x$와 이미지에 대한 라벨 $y$는 정확하게 측정되어야 한다. 무슨 말이냐면 $x$라는 이미지가 정말로 $y$처럼 보여야한다는 것이다. 이때는 샘플에 대한 확신이 곧 이미지의 퀄리티를 반영하므로 $p(y \vert x)$는 low entropy를 가져야하고, 해당 term이 image quality를 나타낸다.

<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089655-7128e7d6-88e8-4e93-895b-891c010ef22a.png" width="800"/>
</p>

확률맵 $p(y \vert x)$를 측정하는 방식은 해당 sample을 통해 학습시킨 inception network를 기준으로 softmax vector를 사용하며, $p(y)$는 모든 샘플에 대한 marginal distribution으로 구한다($p(y) = \frac{1}{N} \sum_{i=1}^N p(y \vert x_i)$). 만약 diversity가 적다면 $p(y)$는 sparse vector(희박한 벡터, one-hot encoding과 같다고 보면 된다)가 되고 반대로 diversity가 크다면 $p(y)$는 dense vector(밀도있는 벡터, entropy가 높은 uniform distribution을 생각하면 된다))가 된다.   
이런 식으로 각 샘플인 $x_i$에 대해 구할 수 있는 inception score IS는,
\[
    IS = exp \left( \frac{1}{W} \sum_{i=1}^N D_{KL} (p(y \vert x_i), p(y)) \right)    
\]

## FID: Frechet Inception Distance
그러나 Inception Score에는 큰 문제가 있는데, 그것은 바로 각 class 별로 단 하나의 이미지만 만들어낼 수 있어도(이런 문제를 mode collapse라고 부른다) diversity가 높게 측정된다는 것이다.   단순히 generator가 각 클래스마다 생성하기 쉬워보이는 샘플에 overfitting되면 IS score가 높다. 그렇기 때문에 정말로 다양한 샘플을 만들 수 있는지에 대한 기준이 되기 힘들다. 이러한 측면에서 inception network를 사용하여 중간 layer에서 feature를 뽑고, 평균인 $\mu$와 공분산 $\Sigma$를 사용하여 다변수 가우시안 분포를 모델링하는 FID 방식이 소개되었다.
\[
    FID(x, g) = \parallel \mu_x - \mu_g \parallel^2_2 + Tr(\Sigma_x + \Sigma_g - 2(\Sigma_x \Sigma_g)^{1/2})    
\]
즉 실제 데이터와 생성 데이터 간의 분포를 비교하고자 하는 식이고, 해당 메트릭은 Inception score에 비해 noise에 강하다는 특징이 있다. 또한 만약 generator가 단 하나의 이미지를 각 클래스마다 만들어내면 이를 IS 지표상으로는 구분을 못했는데, FID에서는 실제 데이터의 분포와 비교를 하다보니 FID 값이 더 안좋게(크게) 나온다. 따라서 다양성에 대한 특성도 반영할 수 있다는 것이다. 그래서 Inception score와 비교하여 FID가 다양성에 대한 지표로서 잘 작동한다.

## LPIPS: Learned Perceptual Image Patch Similarity
<p align="center">
    <img src="https://user-images.githubusercontent.com/79881119/209089658-4e9b9b38-40a4-4325-b1a4-88356fe002d1.png" width="800"/>
</p>
LPIPS라는 메트릭은 비교적 간단하게 확인할 수 있다.
\[
    d(x,~x_0) = \sum_l \frac{1}{H_l W_l} \sum_{h, w} \parallel w_l \odot (\hat{y_{hw}}^l - \hat{y_{0hw}}^l) \parallel_2^2    
\]
Feature extraction model인 AlexNet, VGG, SqueezeNet을 사용하여 각 feature map과의 차이를 구하는 것이다. $x_0$이 기준이 되는 이미지이고 $x$가 측정하고 싶은 이미지라면, 각각의 activation map인 $\hat{y_{hw}}^l, \hat{y_{0hw}}^l$ 사이의 Euclidean distance를 계산한 뒤에 layer weight $w_l$에 대해 이를 각 채널에 대해 평균을 낸 뒤 레이어 별로 구해진 거리들에 대해 평균을 내면 된다. Feature map 간의 거리를 계산한다는 점에서 image patch similarity를 거리 메트릭으로 사용했다고 한다. 여기서 각 레이어별 weight인 $w_l$은 논문을 보면 학습시키는 파라미터로 작용하고, 아마 이러한 내용 때문에 paper 제목이 지어지지 않았나 싶다.
